<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Michel Aractingi</title>
  
  <meta name="author" content="Michel Aractingi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/gif" href="data/images/dog.gif">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Michel Aractingi</name>
              </p>
	      <p> In 2023, I obtained a Ph.D. in robotics and computer science from the National Institute of Applied Sciences (INSA) in Toulouse. I did my Ph.D. thesis at Naver Labs Europe and the Gepetto team at LAAS/CNRS. The main focus of my work revolves around learning control policies for quadruped locomotion. I am supervised by <a href="https://gepettoweb.laas.fr/index.php/Members/PhilippeSou%C3%A8res">Philippe Soueres</a> (LAAS)  and <a href="https://europe.naverlabs.com/people_user/Tomi-Silander/">Tomi Silander</a> (NaverLabs Europe).              
	      I recieved my B.Sc from the University of Balamand in Lebanon in Electrical Engineering and my M.Sc. in data science at the Grenoble Institute of Technology INP. 
	      </p>
              <p>
	      During my master's thesis, I worked under the supervision of <a  href="https://thoth.inrialpes.fr/~schmid/">Cordelia Schmid</a> on imitation learning for manipulation skills from visual input. After that I joined the robot navigation team in <a href="https://europe.naverlabs.com">NaverLabs Europe</a> as a research engineer working on the topic of robot navigation for indoor and crowded environments. 
	      Then, in my Phd I worked with the <a href="https://solo.pal-robotics.com/solo">Solo</a> quadruped and the <a href="https://ieeexplore.ieee.org/document/8793865">MIT's MiniCheetah</a>. I designed, implemented and transfered learned locomotion policies with reinforcement learning for both robots. 
              </p>
	      <p>
	      I recently started a new as a Robotics Machine Learning Engineer at <a href="https://enchanted.tools">Enchanted Tools</a>. 
	      </p>
              <p style="text-align:center">
                <a href="mailto:michel.aractingi@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=FmruvKwAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.youtube.com/playlist?list=PLpQGlhFP2UM2Xq65lhBCQv9wNBnOH8RGc">Youtube</a> &nbsp/&nbsp
                <a href="https://github.com/michel-aractingi/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="data/images/michel-aractingi.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="data/images/photo.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am interested in studying the role of machine learning in robotic control and perception. I prefer working with real robots and deploying learned policies in the wild. I want to use robots to push the limits of the current state of AI algorithms.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
      
			
          <tr>
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='data/images/HRL_quad.gif' width="200">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
		    <papertitle>A Hierarchical Scheme for Adapting Learned Quadruped Locomotion</papertitle>
              <br>
              <strong>Michel Aractingi</strong>,
	      Pierre-Alexandre Leziart,
	      Thomas Flayols,
	      Julien Perez,
	      Tomi Silander,
	      Philippe Soueres
              <br>
              <em>IEEE Humanoids</em>, 2023
              <br>
              <a href="https://hal.science/hal-04174932">paper</a>
              <a href="data/bibtex/hrl_loco.bib">bibtex</a>
	      <a href="https://youtu.be/B92HB964xq8">video</a>
              <p>A hierarchical approach for learning locomotion policies where several aspects of the low-level behaviour can be comanded.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='data/images/solo-bridge.gif' width="200">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
                <papertitle>Controlling the Solo12 Quadruped with Deep Reinforcement Learning</papertitle>
              <br>
              <strong>Michel Aractingi</strong>,
	      Pierre-Alexandre Leziart,
	      Thomas Flayols,
	      Julien Perez,
	      Tomi Silander,
	      Philippe Soueres
              <br>
              <em>Scientific Reports</em>, 2023
              <br>
              <a href="https://hal.laas.fr/hal-03761331/document">paper</a>
              <a href="data/bibtex/solo12.bib">bibtex</a>
	      <a href="https://www.youtube.com/watch?v=t-67qBxNyZI&t">video</a>
              <p>A deep reinforcement learning approach to learn joint-angle control for the solo12 quadruped with a state estimation network.</p>
            </td>
          </tr>



          <tr>
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='data/images/dipcan.png' width="200">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
                <papertitle>DiPCAN: Distilling Privileged Information for Crowd-Aware Navigation</papertitle>
              <br>
	      Gianluca Monaci
              <strong>Michel Aractingi</strong>,
	      Tomi Silander,
              <br>
              <em>RSS 2022, <font color="red"><strong> Nominated for Best Paper Award</strong></font></em>
              <br>
              <a href="http://www.roboticsproceedings.org/rss18/p045.pdf">paper</a>
              <a href="data/bibtex/dipcan.bib">bibtex</a>
	      <a href="https://vimeo.com/705660277">video</a>
              <p>Learning navigation policies in densely crowded environments.</p>
            </td>
          </tr>



          <tr>
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='data/images/solo-gait.png' width="200">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
                <papertitle>Learning to Adapt the Trotting Gait of the Solo Quadruped</papertitle>
              <br>
              <strong>Michel Aractingi</strong>,
	      Pierre-Alexandre Leziart,
	      Thomas Flayols,
	      Julien Perez,
	      Tomi Silander,
	      Philippe Soueres
              <br>
              <em>Preprint</em>, 2021
              <br>
              <a href="https://hal.laas.fr/hal-03409682v1/document">paper</a>
              <a href="data/bibtex/solo-gait.bib">bibtex</a>
	      <p>We propose to augment the model-based controller of the solo12 quadruped with a policy that modifies the gait sequence learned with deep reinforcement learning. </p>
            </td>
            </td>
          </tr>



          <tr>
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='data/images/invariance.png' width="200">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
                <papertitle>Improving the Generalization of Visual Navigation Policies using Invariance Regularization </papertitle>
              <br>
              <strong>Michel Aractingi</strong>,
	      Christopher Dance,
	      Julien Perez,
	      Tomi Silander,
              <br>
              <em>ICML 2019 Workshop RL4RealLife</em>
              <br>
              <a href="https://openreview.net/forum?id=SJel4-c2j4">paper</a>
              <a href="data/bibtex/invariance.bib">bibtex</a>
	      <p>We study the generalization ability of visual navigation agents trained with deep RL. We propose a regularization term to improve their generalization ability.</p>
            </td>
            </td>
          </tr>














        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
	      website's template credit goes to<a href="https://github.com/jonbarron/jonbarron_website"> Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
